{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4c54b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "# AutoGluon\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# 1. 데이터 로드\n",
    "# CSV 파일 경로와 타깃 컬럼명을 프로젝트에 맞게 수정하세요\n",
    "data = pd.read_csv('kidney_disease_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "23034ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 학습/테스트 데이터 분할 (원본 DataFrame 기준)\n",
    "# stratify에는 타깃 컬럼명을 직접 지정합니다\n",
    "df_train, df_test = train_test_split(\n",
    "    data,\n",
    "    test_size=0.2,\n",
    "    stratify=data['class'],\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 특성과 타깃 분리\n",
    "X_train = df_train.drop('class', axis=1)\n",
    "y_train = df_train['class'].astype('category')  # AutoGluon용 카테고리 타입\n",
    "X_test = df_test.drop('class', axis=1)\n",
    "y_test = df_test['class'].astype('category')\n",
    "\n",
    "binary = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "197473c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 평가 함수 정의\n",
    "def evaluate_model(name, y_true, y_pred, y_proba=None, pos_label=None):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='binary', pos_label=pos_label)\n",
    "    rec = recall_score(y_true, y_pred, average='binary', pos_label=pos_label)\n",
    "    f1 = f1_score(y_true, y_pred, average='binary', pos_label=pos_label)\n",
    "    print(f'--- {name} ---')\n",
    "    print(f'Accuracy : {acc:.4f}')\n",
    "    print(f'Precision: {prec:.4f}')\n",
    "    print(f'Recall   : {rec:.4f}')\n",
    "    print(f'F1 Score : {f1:.4f}')\n",
    "    if y_proba is not None:\n",
    "        roc = roc_auc_score(y_true, y_proba, pos_label=pos_label)\n",
    "        print(f'ROC-AUC  : {roc:.4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54cba5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250724_120756\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.12.7\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.5.0: Tue Apr 22 19:54:49 PDT 2025; root:xnu-11417.121.6~2/RELEASE_ARM64_T6000\n",
      "CPU Count:          8\n",
      "Memory Avail:       4.19 GB / 16.00 GB (26.2%)\n",
      "Disk Space Avail:   774.72 GB / 926.35 GB (83.6%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 75s of the 300s of remaining time (25%).\n",
      "/opt/anaconda3/lib/python3.12/site-packages/autogluon/tabular/predictor/predictor.py:1380: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ImportError('ray is required to train folds in parallel for TabularPredictor or HPO for MultiModalPredictor. A quick tip is to install via `pip install \"ray>=2.10.0,<2.40.0\"`')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"/Users/jeong-kyu/Documents/연세대/헬스케어 부트/AutogluonModels/ag-20250724_120756/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 75s\n",
      "AutoGluon will save models to \"/Users/jeong-kyu/Documents/연세대/헬스케어 부트/AutogluonModels/ag-20250724_120756/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    284\n",
      "Train Data Columns: 24\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4203.41 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['Age', 'BP', 'SG', 'Albumin', 'urine_sugar', ...]\n",
      "\t\t('int', [])   : 10 | ['urine_RBC', 'urine_pc', 'urine_pcc', 'urine_bacteria', 'HTN', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 14 | ['Age', 'BP', 'SG', 'Albumin', 'urine_sugar', ...]\n",
      "\t\t('int', ['bool']) : 10 | ['urine_RBC', 'urine_pc', 'urine_pcc', 'urine_bacteria', 'HTN', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t24 features in original data used to generate 24 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 49.93s of the 74.91s of remaining time.\n",
      "\t0.5763\t = Validation score   (f1)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 49.90s of the 74.88s of remaining time.\n",
      "\t0.6016\t = Validation score   (f1)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 49.87s of the 74.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.2`.\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 49.64s of the 74.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.2`.\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 49.48s of the 74.45s of remaining time.\n",
      "\t0.9761\t = Validation score   (f1)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 49.10s of the 74.08s of remaining time.\n",
      "\t0.9714\t = Validation score   (f1)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 48.76s of the 73.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 2551.\n",
      "\tRan out of time, early stopping on iteration 3280.\n",
      "\tRan out of time, early stopping on iteration 6428.\n",
      "\t0.977\t = Validation score   (f1)\n",
      "\t42.48s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 6.22s of the 31.20s of remaining time.\n",
      "\t0.9906\t = Validation score   (f1)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 5.88s of the 30.86s of remaining time.\n",
      "\t0.9906\t = Validation score   (f1)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 5.54s of the 30.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.2`. \n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 5.38s of the 30.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.9813\t = Validation score   (f1)\n",
      "\t3.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1.91s of the 26.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tNot enough time to train first epoch. (Time Required: 0.57s, Time Left: 0.16s)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1.66s of the 26.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.2`.\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1.50s of the 26.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 125.\n",
      "\tRan out of time, early stopping on iteration 128.\n",
      "\tRan out of time, early stopping on iteration 131.\n",
      "\tRan out of time, early stopping on iteration 141.\n",
      "\tRan out of time, early stopping on iteration 143.\n",
      "\tRan out of time, early stopping on iteration 150.\n",
      "\tRan out of time, early stopping on iteration 164.\n",
      "\tRan out of time, early stopping on iteration 195.\n",
      "\t0.9725\t = Validation score   (f1)\n",
      "\t1.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 0.05s of the 25.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 74.91s of the 24.78s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesGini_BAG_L1': 0.667, 'CatBoost_BAG_L1': 0.333}\n",
      "\t0.9953\t = Validation score   (f1)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 24.59s of the 24.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.2`.\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 24.36s of the 24.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.2`.\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 24.15s of the 24.11s of remaining time.\n",
      "\t0.9953\t = Validation score   (f1)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 23.75s of the 23.72s of remaining time.\n",
      "\t0.9907\t = Validation score   (f1)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 23.39s of the 23.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1413.\n",
      "\tRan out of time, early stopping on iteration 1601.\n",
      "\tRan out of time, early stopping on iteration 3903.\n",
      "\t0.9907\t = Validation score   (f1)\n",
      "\t20.91s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 2.43s of the 2.39s of remaining time.\n",
      "\t0.9907\t = Validation score   (f1)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 2.09s of the 2.06s of remaining time.\n",
      "\t0.9907\t = Validation score   (f1)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1.76s of the 1.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.2`. \n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 1.60s of the 1.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.9815\t = Validation score   (f1)\n",
      "\t1.51s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 74.91s of the -0.03s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestGini_BAG_L2': 1.0}\n",
      "\t0.9953\t = Validation score   (f1)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 75.12s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2956.8 rows/s (36 batch size)\n",
      "Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n",
      "Calibrating decision threshold to optimize metric f1 | Checking 51 thresholds...\n",
      "Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
      "\tBase Threshold: 0.500\t| val: 0.9953\n",
      "\tBest Threshold: 0.500\t| val: 0.9953\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/jeong-kyu/Documents/연세대/헬스케어 부트/AutogluonModels/ag-20250724_120756/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   RandomForestEntr_BAG_L1       1.000000   0.971429          f1        0.019046       0.050106   0.271983                 0.019046                0.050106           0.271983            1       True          4\n",
      "1     ExtraTreesGini_BAG_L1       1.000000   0.990566          f1        0.020941       0.049105   0.273398                 0.020941                0.049105           0.273398            1       True          6\n",
      "2     ExtraTreesEntr_BAG_L1       1.000000   0.990566          f1        0.030990       0.050011   0.275514                 0.030990                0.050011           0.275514            1       True          7\n",
      "3            XGBoost_BAG_L2       1.000000   0.981481          f1        0.139869       0.138228  47.999463                 0.022051                0.010726           1.509592            2       True         16\n",
      "4      CatBoost_r177_BAG_L1       0.962963   0.972477          f1        0.009027       0.005982   1.418507                 0.009027                0.005982           1.418507            1       True          9\n",
      "5   RandomForestGini_BAG_L1       0.962963   0.976077          f1        0.019814       0.050350   0.313154                 0.019814                0.050350           0.313154            1       True          3\n",
      "6           CatBoost_BAG_L1       0.962963   0.976959          f1        0.023583       0.005829  42.482271                 0.023583                0.005829          42.482271            1       True          5\n",
      "7       WeightedEnsemble_L2       0.962963   0.995305          f1        0.045525       0.055896  42.931459                 0.001001                0.000962           0.175790            2       True         10\n",
      "8           CatBoost_BAG_L2       0.962963   0.990654          f1        0.134935       0.136420  67.400342                 0.017117                0.008918          20.910471            2       True         13\n",
      "9     ExtraTreesEntr_BAG_L2       0.962963   0.990654          f1        0.136293       0.177445  46.756667                 0.018475                0.049943           0.266796            2       True         15\n",
      "10    ExtraTreesGini_BAG_L2       0.962963   0.990654          f1        0.136650       0.176496  46.761228                 0.018832                0.048994           0.271358            2       True         14\n",
      "11  RandomForestEntr_BAG_L2       0.962963   0.990654          f1        0.137168       0.176748  46.786815                 0.019350                0.049246           0.296944            2       True         12\n",
      "12  RandomForestGini_BAG_L2       0.962963   0.995305          f1        0.138320       0.180115  46.814800                 0.020502                0.052614           0.324929            2       True         11\n",
      "13      WeightedEnsemble_L3       0.962963   0.995305          f1        0.138968       0.181014  46.949112                 0.000648                0.000898           0.134313            3       True         17\n",
      "14           XGBoost_BAG_L1       0.928571   0.981308          f1        0.040160       0.007993   3.419327                 0.040160                0.007993           3.419327            1       True          8\n",
      "15    KNeighborsDist_BAG_L1       0.645161   0.601626          f1        0.013320       0.014225   0.001720                 0.013320                0.014225           0.001720            1       True          2\n",
      "16    KNeighborsUnif_BAG_L1       0.533333   0.576271          f1        0.015463       0.015651   0.003259                 0.015463                0.015651           0.003259            1       True          1\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t76s\t = DyStack   runtime |\t224s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 224s\n",
      "AutoGluon will save models to \"/Users/jeong-kyu/Documents/연세대/헬스케어 부트/AutogluonModels/ag-20250724_120756\"\n",
      "Train Data Rows:    320\n",
      "Train Data Columns: 24\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4315.06 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['Age', 'BP', 'SG', 'Albumin', 'urine_sugar', ...]\n",
      "\t\t('int', [])   : 10 | ['urine_RBC', 'urine_pc', 'urine_pcc', 'urine_bacteria', 'HTN', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 14 | ['Age', 'BP', 'SG', 'Albumin', 'urine_sugar', ...]\n",
      "\t\t('int', ['bool']) : 10 | ['urine_RBC', 'urine_pc', 'urine_pcc', 'urine_bacteria', 'HTN', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t24 features in original data used to generate 24 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 149.51s of the 224.32s of remaining time.\n",
      "\t0.5878\t = Validation score   (f1)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 149.48s of the 224.29s of remaining time.\n",
      "\t0.6214\t = Validation score   (f1)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 149.46s of the 224.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.2`.\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 149.30s of the 224.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.2`.\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 149.14s of the 223.94s of remaining time.\n",
      "\t0.9746\t = Validation score   (f1)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 148.81s of the 223.61s of remaining time.\n",
      "\t0.9746\t = Validation score   (f1)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 148.46s of the 223.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 5750.\n",
      "\t0.9754\t = Validation score   (f1)\n",
      "\t23.76s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 124.65s of the 199.46s of remaining time.\n",
      "\t0.9916\t = Validation score   (f1)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 124.31s of the 199.12s of remaining time.\n",
      "\t0.9874\t = Validation score   (f1)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 123.98s of the 198.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.2`. \n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 123.80s of the 198.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.9752\t = Validation score   (f1)\n",
      "\t3.96s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 119.79s of the 194.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.9796\t = Validation score   (f1)\n",
      "\t3.12s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 116.60s of the 191.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.2`.\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 116.44s of the 191.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 4955.\n",
      "\t0.9636\t = Validation score   (f1)\n",
      "\t19.11s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 97.29s of the 172.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t4.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 92.88s of the 167.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_r131_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.2`.\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 92.73s of the 167.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetFastAI_r191_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.2`. \n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 92.57s of the 167.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 2302.\n",
      "\tRan out of time, early stopping on iteration 2251.\n",
      "\t0.9794\t = Validation score   (f1)\n",
      "\t38.32s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 54.19s of the 129.00s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_r96_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.2`.\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 54.03s of the 128.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.9877\t = Validation score   (f1)\n",
      "\t4.06s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 49.89s of the 124.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.9874\t = Validation score   (f1)\n",
      "\t4.97s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 44.86s of the 119.67s of remaining time.\n",
      "\t0.9874\t = Validation score   (f1)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 44.51s of the 119.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.9675\t = Validation score   (f1)\n",
      "\t3.17s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 41.30s of the 116.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetFastAI_r102_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.2`. \n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 41.14s of the 115.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1258.\n",
      "\tRan out of time, early stopping on iteration 2295.\n",
      "\tRan out of time, early stopping on iteration 2657.\n",
      "\t0.9714\t = Validation score   (f1)\n",
      "\t38.15s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 2.94s of the 77.75s of remaining time.\n",
      "\t0.971\t = Validation score   (f1)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 2.52s of the 77.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_r188_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.2`.\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 2.33s of the 77.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetFastAI_r145_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.2`. \n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 2.17s of the 76.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.9832\t = Validation score   (f1)\n",
      "\t2.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 0.07s of the 74.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r30_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 224.32s of the 74.65s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_r79_BAG_L1': 1.0}\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 74.55s of the 74.50s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.2`.\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 74.39s of the 74.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.2`.\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 74.23s of the 74.18s of remaining time.\n",
      "\t0.9916\t = Validation score   (f1)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 73.88s of the 73.84s of remaining time.\n",
      "\t0.9916\t = Validation score   (f1)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 73.54s of the 73.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 2899.\n",
      "\tRan out of time, early stopping on iteration 3918.\n",
      "\tRan out of time, early stopping on iteration 4063.\n",
      "\tRan out of time, early stopping on iteration 6053.\n",
      "\t0.9958\t = Validation score   (f1)\n",
      "\t67.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 5.82s of the 5.77s of remaining time.\n",
      "\t0.9916\t = Validation score   (f1)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 5.48s of the 5.43s of remaining time.\n",
      "\t0.9916\t = Validation score   (f1)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 5.14s of the 5.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.2`. \n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 4.98s of the 4.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.9958\t = Validation score   (f1)\n",
      "\t3.57s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 224.32s of the 1.26s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_r79_BAG_L1': 1.0}\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 223.24s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1215.3 rows/s (40 batch size)\n",
      "Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n",
      "Calibrating decision threshold to optimize metric f1 | Checking 51 thresholds...\n",
      "Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
      "\tBase Threshold: 0.500\t| val: 1.0000\n",
      "\tBest Threshold: 0.500\t| val: 1.0000\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/jeong-kyu/Documents/연세대/헬스케어 부트/AutogluonModels/ag-20250724_120756\")\n"
     ]
    }
   ],
   "source": [
    "# 5. AutoGluon을 활용한 모델 학습\n",
    "train_data = X_train.copy()\n",
    "train_data['class'] = y_train\n",
    "predictor = TabularPredictor(\n",
    "    label='class',\n",
    "    eval_metric='f1'\n",
    ").fit(\n",
    "    train_data,\n",
    "    time_limit=300,\n",
    "    presets='best_quality'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "34184c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model explicitly saved to: autogluon_model\n"
     ]
    }
   ],
   "source": [
    "# 5-1. 학습된 모델 명시적 저장\n",
    "model_save_path = 'autogluon_model'\n",
    "predictor.save(model_save_path)\n",
    "print(f'Model explicitly saved to: {model_save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9dca9f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative class: 0, Positive class: 1\n"
     ]
    }
   ],
   "source": [
    "# 6. positive/negative 클래스 레이블 설정\n",
    "# 0=not ckd, 1=ckd\n",
    "negative_label = 0\n",
    "positive_label = 1\n",
    "print(f'Negative class: {negative_label}, Positive class: {positive_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b28caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Leaderboard ===\n",
      "                        model  score_test  score_val eval_metric  \\\n",
      "0        CatBoost_r137_BAG_L1    0.983051   0.967480          f1   \n",
      "1             CatBoost_BAG_L1    0.983051   0.975410          f1   \n",
      "2        CatBoost_r177_BAG_L1    0.983051   0.963563          f1   \n",
      "3     RandomForestEntr_BAG_L1    0.983051   0.974576          f1   \n",
      "4         CatBoost_r13_BAG_L1    0.983051   0.971429          f1   \n",
      "5          XGBoost_r89_BAG_L1    0.983051   0.983193          f1   \n",
      "6       ExtraTreesEntr_BAG_L1    0.983051   0.987448          f1   \n",
      "7       ExtraTrees_r42_BAG_L1    0.983051   0.987448          f1   \n",
      "8       ExtraTreesGini_BAG_L1    0.983051   0.991597          f1   \n",
      "9    RandomForest_r195_BAG_L1    0.983051   0.970954          f1   \n",
      "10    RandomForestGini_BAG_L1    0.983051   0.974576          f1   \n",
      "11         CatBoost_r9_BAG_L1    0.983051   0.979424          f1   \n",
      "12             XGBoost_BAG_L1    0.983051   0.975207          f1   \n",
      "13         XGBoost_r33_BAG_L1    0.983051   0.987448          f1   \n",
      "14      ExtraTreesEntr_BAG_L2    0.983051   0.991597          f1   \n",
      "15      ExtraTreesGini_BAG_L2    0.983051   0.991597          f1   \n",
      "16    RandomForestGini_BAG_L2    0.983051   0.991597          f1   \n",
      "17    RandomForestEntr_BAG_L2    0.983051   0.991597          f1   \n",
      "18  NeuralNetTorch_r22_BAG_L1    0.966667   0.987654          f1   \n",
      "19            CatBoost_BAG_L2    0.966667   0.995816          f1   \n",
      "20      NeuralNetTorch_BAG_L1    0.950820   0.979592          f1   \n",
      "21  NeuralNetTorch_r79_BAG_L1    0.950820   1.000000          f1   \n",
      "22        WeightedEnsemble_L3    0.950820   1.000000          f1   \n",
      "23        WeightedEnsemble_L2    0.950820   1.000000          f1   \n",
      "24             XGBoost_BAG_L2    0.950820   0.995816          f1   \n",
      "25      KNeighborsDist_BAG_L1    0.553846   0.621429          f1   \n",
      "26      KNeighborsUnif_BAG_L1    0.521739   0.587814          f1   \n",
      "\n",
      "    pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  \\\n",
      "0         0.011636       0.005143    3.172397                 0.011636   \n",
      "1         0.017887       0.005548   23.764508                 0.017887   \n",
      "2         0.019439       0.005910   19.110902                 0.019439   \n",
      "3         0.020148       0.049729    0.287034                 0.020148   \n",
      "4         0.026365       0.006240   38.147869                 0.026365   \n",
      "5         0.027777       0.008194    2.045145                 0.027777   \n",
      "6         0.030922       0.049778    0.270984                 0.030922   \n",
      "7         0.032174       0.049043    0.284607                 0.032174   \n",
      "8         0.033001       0.049692    0.276588                 0.033001   \n",
      "9         0.033291       0.049524    0.354572                 0.033291   \n",
      "10        0.033340       0.049858    0.268721                 0.033340   \n",
      "11        0.037061       0.009128   38.315904                 0.037061   \n",
      "12        0.045894       0.008781    3.960491                 0.045894   \n",
      "13        0.053895       0.008159    4.974117                 0.053895   \n",
      "14        0.260595       0.212444   48.433821                 0.030530   \n",
      "15        0.260994       0.212391   48.438390                 0.030929   \n",
      "16        0.261972       0.212613   48.441553                 0.031907   \n",
      "17        0.262376       0.211884   48.447981                 0.032311   \n",
      "18        0.049670       0.032462    4.064776                 0.049670   \n",
      "19        0.270001       0.173145  115.820939                 0.039936   \n",
      "20        0.046218       0.030858    3.121849                 0.046218   \n",
      "21        0.057495       0.032794    4.327273                 0.057495   \n",
      "22        0.058391       0.033613    4.420205                 0.000896   \n",
      "23        0.058406       0.033766    4.422628                 0.000911   \n",
      "24        0.269484       0.172329   51.730201                 0.039419   \n",
      "25        0.015273       0.012823    0.001773                 0.015273   \n",
      "26        0.015880       0.015612    0.003443                 0.015880   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.005143           3.172397            1       True   \n",
      "1                 0.005548          23.764508            1       True   \n",
      "2                 0.005910          19.110902            1       True   \n",
      "3                 0.049729           0.287034            1       True   \n",
      "4                 0.006240          38.147869            1       True   \n",
      "5                 0.008194           2.045145            1       True   \n",
      "6                 0.049778           0.270984            1       True   \n",
      "7                 0.049043           0.284607            1       True   \n",
      "8                 0.049692           0.276588            1       True   \n",
      "9                 0.049524           0.354572            1       True   \n",
      "10                0.049858           0.268721            1       True   \n",
      "11                0.009128          38.315904            1       True   \n",
      "12                0.008781           3.960491            1       True   \n",
      "13                0.008159           4.974117            1       True   \n",
      "14                0.049991           0.269445            2       True   \n",
      "15                0.049938           0.274014            2       True   \n",
      "16                0.050160           0.277177            2       True   \n",
      "17                0.049431           0.283606            2       True   \n",
      "18                0.032462           4.064776            1       True   \n",
      "19                0.010692          67.656563            2       True   \n",
      "20                0.030858           3.121849            1       True   \n",
      "21                0.032794           4.327273            1       True   \n",
      "22                0.000819           0.092932            3       True   \n",
      "23                0.000972           0.095355            2       True   \n",
      "24                0.009876           3.565825            2       True   \n",
      "25                0.012823           0.001773            1       True   \n",
      "26                0.015612           0.003443            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0          16  \n",
      "1           5  \n",
      "2          10  \n",
      "3           4  \n",
      "4          17  \n",
      "5          19  \n",
      "6           7  \n",
      "7          15  \n",
      "8           6  \n",
      "9          18  \n",
      "10          3  \n",
      "11         12  \n",
      "12          8  \n",
      "13         14  \n",
      "14         25  \n",
      "15         24  \n",
      "16         21  \n",
      "17         22  \n",
      "18         13  \n",
      "19         23  \n",
      "20          9  \n",
      "21         11  \n",
      "22         27  \n",
      "23         20  \n",
      "24         26  \n",
      "25          2  \n",
      "26          1  \n",
      "Best model: WeightedEnsemble_L2\n",
      "=== Hyperparameters of Best Model ===\n",
      "{'base_model_names': ['NeuralNetTorch_r79_BAG_L1'], 'base_models_dict': {}, 'base_model_paths_dict': {'KNeighborsUnif_BAG_L1': '../KNeighborsUnif_BAG_L1', 'KNeighborsDist_BAG_L1': '../KNeighborsDist_BAG_L1', 'RandomForestGini_BAG_L1': '../RandomForestGini_BAG_L1', 'RandomForestEntr_BAG_L1': '../RandomForestEntr_BAG_L1', 'CatBoost_BAG_L1': '../CatBoost_BAG_L1', 'ExtraTreesGini_BAG_L1': '../ExtraTreesGini_BAG_L1', 'ExtraTreesEntr_BAG_L1': '../ExtraTreesEntr_BAG_L1', 'XGBoost_BAG_L1': '../XGBoost_BAG_L1', 'NeuralNetTorch_BAG_L1': '../NeuralNetTorch_BAG_L1', 'CatBoost_r177_BAG_L1': '../CatBoost_r177_BAG_L1', 'NeuralNetTorch_r79_BAG_L1': '../NeuralNetTorch_r79_BAG_L1', 'CatBoost_r9_BAG_L1': '../CatBoost_r9_BAG_L1', 'NeuralNetTorch_r22_BAG_L1': '../NeuralNetTorch_r22_BAG_L1', 'XGBoost_r33_BAG_L1': '../XGBoost_r33_BAG_L1', 'ExtraTrees_r42_BAG_L1': '../ExtraTrees_r42_BAG_L1', 'CatBoost_r137_BAG_L1': '../CatBoost_r137_BAG_L1', 'CatBoost_r13_BAG_L1': '../CatBoost_r13_BAG_L1', 'RandomForest_r195_BAG_L1': '../RandomForest_r195_BAG_L1', 'XGBoost_r89_BAG_L1': '../XGBoost_r89_BAG_L1'}, 'base_model_types_dict': {'KNeighborsUnif_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'KNeighborsDist_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'RandomForestGini_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'RandomForestEntr_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'CatBoost_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'ExtraTreesGini_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'ExtraTreesEntr_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'XGBoost_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'NeuralNetTorch_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'CatBoost_r177_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'NeuralNetTorch_r79_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'CatBoost_r9_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'NeuralNetTorch_r22_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'XGBoost_r33_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'ExtraTrees_r42_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'CatBoost_r137_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'CatBoost_r13_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'RandomForest_r195_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>, 'XGBoost_r89_BAG_L1': <class 'autogluon.core.models.ensemble.stacker_ensemble_model.StackerEnsembleModel'>}, 'base_model_performances_dict': {'KNeighborsUnif_BAG_L1': 0.5878136200716846, 'KNeighborsDist_BAG_L1': 0.6214285714285714, 'RandomForestGini_BAG_L1': 0.9745762711864406, 'RandomForestEntr_BAG_L1': 0.9745762711864406, 'CatBoost_BAG_L1': 0.9754098360655737, 'ExtraTreesGini_BAG_L1': 0.9915966386554622, 'ExtraTreesEntr_BAG_L1': 0.9874476987447699, 'XGBoost_BAG_L1': 0.9752066115702479, 'NeuralNetTorch_BAG_L1': 0.9795918367346939, 'CatBoost_r177_BAG_L1': 0.9635627530364372, 'NeuralNetTorch_r79_BAG_L1': 1.0, 'CatBoost_r9_BAG_L1': 0.9794238683127572, 'NeuralNetTorch_r22_BAG_L1': 0.9876543209876543, 'XGBoost_r33_BAG_L1': 0.9874476987447699, 'ExtraTrees_r42_BAG_L1': 0.9874476987447699, 'CatBoost_r137_BAG_L1': 0.967479674796748, 'CatBoost_r13_BAG_L1': 0.9714285714285714, 'RandomForest_r195_BAG_L1': 0.970954356846473, 'XGBoost_r89_BAG_L1': 0.9831932773109243}, 'base_model_types_inner_dict': {'KNeighborsUnif_BAG_L1': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'KNeighborsDist_BAG_L1': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'RandomForestGini_BAG_L1': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'RandomForestEntr_BAG_L1': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'CatBoost_BAG_L1': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'ExtraTreesGini_BAG_L1': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'ExtraTreesEntr_BAG_L1': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'XGBoost_BAG_L1': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'NeuralNetTorch_BAG_L1': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'CatBoost_r177_BAG_L1': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'NeuralNetTorch_r79_BAG_L1': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'CatBoost_r9_BAG_L1': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'NeuralNetTorch_r22_BAG_L1': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'XGBoost_r33_BAG_L1': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'ExtraTrees_r42_BAG_L1': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'CatBoost_r137_BAG_L1': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'CatBoost_r13_BAG_L1': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'RandomForest_r195_BAG_L1': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'XGBoost_r89_BAG_L1': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'model_base': <autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel object at 0x16a958b60>, 'random_state': 2, 'path': '/Users/jeong-kyu/Documents/연세대/헬스케어 부트/AutogluonModels/ag-20250724_120756/models', 'name': 'WeightedEnsemble_L2', 'hyperparameters': {'save_bag_folds': True}}\n"
     ]
    }
   ],
   "source": [
    "# 7. 학습 결과 요약 (리더보드, 최적 모델 및 하이퍼파라미터)\n",
    "leaderboard = predictor.leaderboard(df_test, silent=True)\n",
    "print('=== Leaderboard ===')\n",
    "print(leaderboard)\n",
    "\n",
    "# 최적 모델 이름 (deprecation 해결: model_best 속성 사용)\n",
    "best_model = predictor.model_best\n",
    "print(f'Best model: {best_model}')\n",
    "\n",
    "# 하이퍼파라미터 확인\n",
    "best_model_obj = predictor._trainer.load_model(best_model)\n",
    "print('=== Hyperparameters of Best Model ===')\n",
    "print(best_model_obj.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9e219413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Leaderboard ===\n",
      "                        model  score_test  score_val eval_metric  \\\n",
      "0        CatBoost_r137_BAG_L1    0.983051   0.967480          f1   \n",
      "1        CatBoost_r177_BAG_L1    0.983051   0.963563          f1   \n",
      "2             CatBoost_BAG_L1    0.983051   0.975410          f1   \n",
      "3         CatBoost_r13_BAG_L1    0.983051   0.971429          f1   \n",
      "4          XGBoost_r89_BAG_L1    0.983051   0.983193          f1   \n",
      "5          CatBoost_r9_BAG_L1    0.983051   0.979424          f1   \n",
      "6     RandomForestGini_BAG_L1    0.983051   0.974576          f1   \n",
      "7       ExtraTreesGini_BAG_L1    0.983051   0.991597          f1   \n",
      "8       ExtraTrees_r42_BAG_L1    0.983051   0.987448          f1   \n",
      "9     RandomForestEntr_BAG_L1    0.983051   0.974576          f1   \n",
      "10      ExtraTreesEntr_BAG_L1    0.983051   0.987448          f1   \n",
      "11   RandomForest_r195_BAG_L1    0.983051   0.970954          f1   \n",
      "12         XGBoost_r33_BAG_L1    0.983051   0.987448          f1   \n",
      "13             XGBoost_BAG_L1    0.983051   0.975207          f1   \n",
      "14    RandomForestEntr_BAG_L2    0.983051   0.991597          f1   \n",
      "15    RandomForestGini_BAG_L2    0.983051   0.991597          f1   \n",
      "16      ExtraTreesEntr_BAG_L2    0.983051   0.991597          f1   \n",
      "17      ExtraTreesGini_BAG_L2    0.983051   0.991597          f1   \n",
      "18  NeuralNetTorch_r22_BAG_L1    0.966667   0.987654          f1   \n",
      "19            CatBoost_BAG_L2    0.966667   0.995816          f1   \n",
      "20      NeuralNetTorch_BAG_L1    0.950820   0.979592          f1   \n",
      "21  NeuralNetTorch_r79_BAG_L1    0.950820   1.000000          f1   \n",
      "22        WeightedEnsemble_L2    0.950820   1.000000          f1   \n",
      "23        WeightedEnsemble_L3    0.950820   1.000000          f1   \n",
      "24             XGBoost_BAG_L2    0.950820   0.995816          f1   \n",
      "25      KNeighborsDist_BAG_L1    0.553846   0.621429          f1   \n",
      "26      KNeighborsUnif_BAG_L1    0.521739   0.587814          f1   \n",
      "\n",
      "    pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  \\\n",
      "0         0.009044       0.005143    3.172397                 0.009044   \n",
      "1         0.012233       0.005910   19.110902                 0.012233   \n",
      "2         0.013343       0.005548   23.764508                 0.013343   \n",
      "3         0.017826       0.006240   38.147869                 0.017826   \n",
      "4         0.024271       0.008194    2.045145                 0.024271   \n",
      "5         0.028577       0.009128   38.315904                 0.028577   \n",
      "6         0.030251       0.049858    0.268721                 0.030251   \n",
      "7         0.030312       0.049692    0.276588                 0.030312   \n",
      "8         0.030621       0.049043    0.284607                 0.030621   \n",
      "9         0.030772       0.049729    0.287034                 0.030772   \n",
      "10        0.032309       0.049778    0.270984                 0.032309   \n",
      "11        0.032764       0.049524    0.354572                 0.032764   \n",
      "12        0.039043       0.008159    4.974117                 0.039043   \n",
      "13        0.047977       0.008781    3.960491                 0.047977   \n",
      "14        0.221864       0.211884   48.447981                 0.029933   \n",
      "15        0.222821       0.212613   48.441553                 0.030890   \n",
      "16        0.223119       0.212444   48.433821                 0.031188   \n",
      "17        0.223914       0.212391   48.438390                 0.031983   \n",
      "18        0.043281       0.032462    4.064776                 0.043281   \n",
      "19        0.218432       0.173145  115.820939                 0.026501   \n",
      "20        0.045622       0.030858    3.121849                 0.045622   \n",
      "21        0.048204       0.032794    4.327273                 0.048204   \n",
      "22        0.048927       0.033766    4.422628                 0.000723   \n",
      "23        0.049037       0.033613    4.420205                 0.000833   \n",
      "24        0.226285       0.172329   51.730201                 0.034354   \n",
      "25        0.015544       0.012823    0.001773                 0.015544   \n",
      "26        0.047090       0.015612    0.003443                 0.047090   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.005143           3.172397            1       True   \n",
      "1                 0.005910          19.110902            1       True   \n",
      "2                 0.005548          23.764508            1       True   \n",
      "3                 0.006240          38.147869            1       True   \n",
      "4                 0.008194           2.045145            1       True   \n",
      "5                 0.009128          38.315904            1       True   \n",
      "6                 0.049858           0.268721            1       True   \n",
      "7                 0.049692           0.276588            1       True   \n",
      "8                 0.049043           0.284607            1       True   \n",
      "9                 0.049729           0.287034            1       True   \n",
      "10                0.049778           0.270984            1       True   \n",
      "11                0.049524           0.354572            1       True   \n",
      "12                0.008159           4.974117            1       True   \n",
      "13                0.008781           3.960491            1       True   \n",
      "14                0.049431           0.283606            2       True   \n",
      "15                0.050160           0.277177            2       True   \n",
      "16                0.049991           0.269445            2       True   \n",
      "17                0.049938           0.274014            2       True   \n",
      "18                0.032462           4.064776            1       True   \n",
      "19                0.010692          67.656563            2       True   \n",
      "20                0.030858           3.121849            1       True   \n",
      "21                0.032794           4.327273            1       True   \n",
      "22                0.000972           0.095355            2       True   \n",
      "23                0.000819           0.092932            3       True   \n",
      "24                0.009876           3.565825            2       True   \n",
      "25                0.012823           0.001773            1       True   \n",
      "26                0.015612           0.003443            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0          16  \n",
      "1          10  \n",
      "2           5  \n",
      "3          17  \n",
      "4          19  \n",
      "5          12  \n",
      "6           3  \n",
      "7           6  \n",
      "8          15  \n",
      "9           4  \n",
      "10          7  \n",
      "11         18  \n",
      "12         14  \n",
      "13          8  \n",
      "14         22  \n",
      "15         21  \n",
      "16         25  \n",
      "17         24  \n",
      "18         13  \n",
      "19         23  \n",
      "20          9  \n",
      "21         11  \n",
      "22         20  \n",
      "23         27  \n",
      "24         26  \n",
      "25          2  \n",
      "26          1  \n",
      "Best model: WeightedEnsemble_L2\n"
     ]
    }
   ],
   "source": [
    "# 8. 학습 결과 요약\n",
    "leaderboard = predictor.leaderboard(df_test, silent=True)\n",
    "print('=== Leaderboard ===')\n",
    "print(leaderboard)\n",
    "best_model = predictor.model_best\n",
    "print(f'Best model: {best_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2ce99ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Metrics for All Models ===\n",
      "--- Metrics for Model: KNeighborsUnif_BAG_L1 ---\n",
      "Accuracy : 0.5875\n",
      "Precision: 0.4615\n",
      "Recall   : 0.6000\n",
      "F1 Score : 0.5217\n",
      "ROC-AUC  : 0.6377\n",
      "--- Metrics for Model: KNeighborsDist_BAG_L1 ---\n",
      "Accuracy : 0.6375\n",
      "Precision: 0.5143\n",
      "Recall   : 0.6000\n",
      "F1 Score : 0.5538\n",
      "ROC-AUC  : 0.6763\n",
      "--- Metrics for Model: RandomForestGini_BAG_L1 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 1.0000\n",
      "--- Metrics for Model: RandomForestEntr_BAG_L1 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 1.0000\n",
      "--- Metrics for Model: CatBoost_BAG_L1 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 1.0000\n",
      "--- Metrics for Model: ExtraTreesGini_BAG_L1 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 1.0000\n",
      "--- Metrics for Model: ExtraTreesEntr_BAG_L1 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 1.0000\n",
      "--- Metrics for Model: XGBoost_BAG_L1 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 0.9987\n",
      "--- Metrics for Model: NeuralNetTorch_BAG_L1 ---\n",
      "Accuracy : 0.9625\n",
      "Precision: 0.9355\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9508\n",
      "ROC-AUC  : 0.9987\n",
      "--- Metrics for Model: CatBoost_r177_BAG_L1 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 1.0000\n",
      "--- Metrics for Model: NeuralNetTorch_r79_BAG_L1 ---\n",
      "Accuracy : 0.9625\n",
      "Precision: 0.9355\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9508\n",
      "ROC-AUC  : 0.9987\n",
      "--- Metrics for Model: CatBoost_r9_BAG_L1 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 1.0000\n",
      "--- Metrics for Model: NeuralNetTorch_r22_BAG_L1 ---\n",
      "Accuracy : 0.9750\n",
      "Precision: 0.9667\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9667\n",
      "ROC-AUC  : 0.9987\n",
      "--- Metrics for Model: XGBoost_r33_BAG_L1 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 1.0000\n",
      "--- Metrics for Model: ExtraTrees_r42_BAG_L1 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 1.0000\n",
      "--- Metrics for Model: CatBoost_r137_BAG_L1 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 1.0000\n",
      "--- Metrics for Model: CatBoost_r13_BAG_L1 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 1.0000\n",
      "--- Metrics for Model: RandomForest_r195_BAG_L1 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 1.0000\n",
      "--- Metrics for Model: XGBoost_r89_BAG_L1 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 1.0000\n",
      "--- Metrics for Model: WeightedEnsemble_L2 ---\n",
      "Accuracy : 0.9625\n",
      "Precision: 0.9355\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9508\n",
      "ROC-AUC  : 0.9987\n",
      "--- Metrics for Model: RandomForestGini_BAG_L2 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 0.9987\n",
      "--- Metrics for Model: RandomForestEntr_BAG_L2 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 0.9987\n",
      "--- Metrics for Model: CatBoost_BAG_L2 ---\n",
      "Accuracy : 0.9750\n",
      "Precision: 0.9667\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9667\n",
      "ROC-AUC  : 0.9987\n",
      "--- Metrics for Model: ExtraTreesGini_BAG_L2 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 0.9987\n",
      "--- Metrics for Model: ExtraTreesEntr_BAG_L2 ---\n",
      "Accuracy : 0.9875\n",
      "Precision: 1.0000\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9831\n",
      "ROC-AUC  : 0.9987\n",
      "--- Metrics for Model: XGBoost_BAG_L2 ---\n",
      "Accuracy : 0.9625\n",
      "Precision: 0.9355\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9508\n",
      "ROC-AUC  : 0.9827\n",
      "--- Metrics for Model: WeightedEnsemble_L3 ---\n",
      "Accuracy : 0.9625\n",
      "Precision: 0.9355\n",
      "Recall   : 0.9667\n",
      "F1 Score : 0.9508\n",
      "ROC-AUC  : 0.9987\n"
     ]
    }
   ],
   "source": [
    "# 9. 모든 모델별 평가 지표 출력\n",
    "# 테스트용 DataFrame 준비\n",
    "test_data = X_test.copy()\n",
    "test_data['class'] = y_test\n",
    "\n",
    " # 모델 이름 리스트 가져오기\n",
    "model_names = predictor.model_names() if callable(predictor.model_names) else predictor.model_names\n",
    "print('=== Metrics for All Models ===')\n",
    "for model in model_names:\n",
    "     print(f\"--- Metrics for Model: {model} ---\")\n",
    "     # AutoGluon evaluate 메서드로 지표 계산\n",
    "     results = predictor.evaluate(test_data, model=model, auxiliary_metrics=True)\n",
    "     # 주요 평가지표 출력\n",
    "     print(f\"Accuracy : {results['accuracy']:.4f}\")\n",
    "     print(f\"Precision: {results['precision']:.4f}\")\n",
    "     print(f\"Recall   : {results['recall']:.4f}\")\n",
    "     print(f\"F1 Score : {results['f1']:.4f}\")\n",
    "     if 'roc_auc' in results:\n",
    "         print(f\"ROC-AUC  : {results['roc_auc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3edf1d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved in predictor.path: /Users/jeong-kyu/Documents/연세대/헬스케어 부트/AutogluonModels/ag-20250724_120756\n"
     ]
    }
   ],
   "source": [
    "# 8. 모델 저장 경로 확인\n",
    "model_dir = predictor.path  # AutoGluon 기본 저장 경로\n",
    "print(f'Models saved in predictor.path: {model_dir}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
